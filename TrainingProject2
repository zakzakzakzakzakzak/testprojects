#!/usr/bin/env python
# coding: utf-8

# In[1]:


# Analyzing mobile app data


# In[2]:


## Analyzing data for developers to understand what types of apps are more likely to encourage customer engagement


# In[3]:




opened_file_apple = open('/Users/admin/Documents/AAT/Python/AppDataGuidedProject/AppleStore.csv')
opened_file_playstore = open('/Users/admin/Documents/AAT/Python/AppDataGuidedProject/googleplaystore.csv')


# In[4]:


def explore_data(dataset, start, end, rows_and_columns=True):
    dataset_slice = dataset[start:end]    
    for row in dataset_slice:
        print(row)
        print('\n') # adds a new empty line after each row

    if rows_and_columns:
        print('Number of rows:', len(dataset))
        print('Number of columns:', len(dataset[0]))


# In[5]:


from csv import reader


# In[6]:


read_file_apple = reader(opened_file_apple)
read_file_playstore = reader(opened_file_playstore)


# In[7]:


ios = (list(read_file_apple))
ios_sample = ios[1:4]
google = list(read_file_playstore)
google_sample = google[1:4]


# In[167]:



explore_data(google_sample,1,7)


# In[9]:


print(ios[0])
print(google[0])


# In[221]:


## in cells below a row from the google dataset was deleted due to a fault in the data


# In[222]:


del google[10473]


# In[223]:


del google[10472]


# In[224]:


print(google[10471])


# In[226]:


## Below for loop separated out a list of the unique aps that appear within the dataset without any duplicates, and a separate depository for duplicate rows


# In[227]:


duplicated_apps =[]
unique_apps=[]
for app in google:
    name = app[0]
    if name in unique_apps:
        duplicated_apps.append(name)
    else:
        unique_apps.append(name)
print(len(unique_apps))
print(len(duplicated_apps))
            


# In[234]:


## The above code demonstrates duplicate data within the google play store data set. as such we want to remove the duplicate only leaving the most recent entry for a given app, we will dtermine this by looking at which of the duplicate entries has the largest review count and take that as the most recent


# In[235]:


print(google[0])


# In[16]:


## cell below is creating a dictionary to show the most rated version of each unique app in the google dataset


# In[232]:


reviews_max={}
for each in google[1:]:
    name = each[0]
    n_reviews= float(each[3])
    if name in reviews_max and reviews_max[name] < n_reviews:
        reviews_max[name] = n_reviews
    elif name not in reviews_max:
        reviews_max[name] = n_reviews
print((reviews_max))
        


# In[230]:


## final cleaning below to produce a list of apps which are all unique and are the latest version of their respective datas


# In[233]:


android_clean=[]
already_added=[]
for each in google[1:]:
    name = each[0]
    no_reviews = float(each[3])
    if  no_reviews == reviews_max[name] and name not in already_added:
        android_clean.append(each)
        already_added.append(name)
    
print((android_clean))
        
    


# In[236]:


## the cell below is checking that there are no duplicates in the apple dataset


# In[237]:


appcount = 0
for each in ios[1:]:
    name = each[0]
    for row in ios[1:]:
        name1 = row[0]
        if name == name1:
            appcount =+1
    if appcount > 1:
        print('Multiple '+ name)
        


# In[238]:


def englishcheck(a_string):
    nonenglishcount = 0
    for character in a_string:
        if ord(character) > 127:
            nonenglishcount +=1
    if nonenglishcount > 3:
        return False
    
    else:
        return True


# In[239]:


## the below cell is removing non english apps from the google and apple datasets


# In[240]:


englishandroidclean = []
for each in android_clean:
    name = each[0]
    if englishcheck(name):
        englishandroidclean.append(each)
        
print(len(englishandroidclean))

englishiosclean = []
for each in ios:
    name = each[1]
    if englishcheck(name):
        englishiosclean.append(each)
print(len(englishiosclean))
    


# In[241]:


## the cell below creates a new list only containing apps that are free


# In[242]:


freegoogle =[]
for each in englishandroidclean:
    price = each[7]
    if price == '0':
        freegoogle.append(each)
print(len(freegoogle))
    


# In[243]:


freeapple =[]
for each in englishiosclean:
    price = each[4]
    if price == '0.0':
        freeapple.append(each)
print(len(freeapple))


# In[244]:


## data cleaning is now complete, now we are looking for successful apps in both the google and apple markets


# In[245]:


def freq_table(dataset, index):
    table = {}
    perctable = {}
    total = len(dataset)
    for row in dataset:
        value = row[index]
        if value in table:
            table[value]+=1
        else:
            table[value]=1
    for each in table:
        amount = table[each]
        percentage = (amount/total)*100
        perctable[each] = percentage
    return perctable


    


# In[246]:


def display_table(dataset, index):
    table = freq_table(dataset, index)
    table_display = []
    for key in table:
        key_val_as_tuple = (table[key], key)
        table_display.append(key_val_as_tuple)

    table_sorted = sorted(table_display, reverse = True)
    for entry in table_sorted:
        print(entry[1],':',entry[0])
    return(table_sorted)


# In[247]:


template_table = display_table(freegoogle, 9)


# In[248]:


applegenretable = display_table(freeapple,11)


# In[249]:


display_table(freegoogle,1)


# In[250]:


def freq_table2(dataset, index):
    table = {}
    perctable = {}
    total = len(dataset)
    for row in dataset:
        value = row[index]
        if value in table:
            table[value]+=1
        else:
            table[value]=1
    return table


# In[251]:


frequencytable = freq_table2(freeapple, 11)
print(frequencytable)


# In[252]:


installtable = {}

for each in freeapple[1:]:
    installs = float(each[5])
    genre = each[11]
    if genre not in installtable:
            installtable[genre] = installs
    elif genre in installtable:
            installtable[genre] += installs

print(installtable)
        


# In[253]:


averagedtable = {}
for each in frequencytable:
    for key in installtable:
        if each == key:
            averagedtable[each] = (installtable[key]/frequencytable[each])
print(averagedtable)


# In[254]:


## the above cells take the frequency count for genre on the appstore, and also the total installs per genre category, to average the amount of installs per category as a way to determine likeliest app genre to be popular


# In[220]:



categoriesandroid = freq_table(freegoogle,1) # the categories column
for category in categoriesandroid:
    total = 0
    len_category = 0
    for app in freegoogle:
        category_app = app[1]
        if category_app == category:
            n_installs = app[5]
            n_installs = n_installs.replace('+','')
            n_installs = n_installs.replace(',','')
            total += float(n_installs)
            len_category +=1
    average_n_installs = total/len_category
    print(category,':',average_n_installs)


